# Week April 7th to 13th.

## QHD

- [ ] Research direction??

## Math Reading

- [ ] Kreyszig section 2.4
- [ ] Kreyszig section 2.5
- [ ] Kreyszig section 2.6
- [ ] Kreyszig section 2.7
- [ ] Kreyszig section 2.8
- [ ] Kreyszig section 2.9

## Research Reading

- [ ] Chapter 5 Hyperbolic Discounting Labour Supply and Growth
- [ ] Chapter 6 Hyperbolic Discounting and Macroeconomic Policy
- [ ] The trouble with rational expectations in Heterogenous agent model: A challenge for Macroeconomics
- [ ] Present-bias amplifies the household balance sheet channels of macroeconomic policy

## Deep Learning Reading

- [ ] Keep working on the DL on DSGE code


## Coursework

- [x] List the Assignments ( Monday 0.5 hours)
- [ ] Network recording wk 1-6
- [ ] DG recording wk 1-6
- [ ] Fractal recording wk 1-6
- [x] ECMT assignment 6 due wk 7
- [ ] Fractal midterm wk7 monday







Total budget 60~70 hours


## DP Reading (20 hours)

### DP2: Section 2.1 Markov Decision Process

- [ ] Section 2.1.1 Finite State MDPs (Monday: March 31st)
- [ ] Section 2.1.2. Finite MDPs in continuous time (Tuesday: April 1st)
- [ ] Section 2.1.3. Weak Feller MDPs (Wednesday: April 2nd)
- [ ] Section 2.1.4 Strong Feller MDPs (Thursday: April 3rd)

### Neuro-dynamic programming 
Friday to Sunday: April 4th, 5th 6th.
- [ ] Chapter 1
- [ ] Chapter 2


## QHD (10 hours)
Finish writing the code of PBMA

- [x] Understand Aiyagari code from QuantEcon (March 30)
- [x] Modify the Aiyagari code to solve for continuation value function  (March 30)
- [x] Solve for the short-run value function  (March 30)
- [x] Solve for equilibrium  (March 30)
- [x] Plot the stationary asset distribution
- [ ] Modify the code to get some simulation results.  (March 30)

## Functional Analysis (7 hours)

- [ ] Kreyszig chapter 3 and exercises (1 hour per day)

## Deep Learning (14 hours)

Read Deep Learning for solving dynamic economic models by Lilia Maliar, Serguei Maliar and Pablo Winant.

- [ ] First time reading: Get the most important idea, and obtain some basic facts (Monday 2 hours)
- [ ] 5-6 quick pass to get enough basic understanding (Tuesday, Wednesday: 2 hours per day)
- [ ] 5-6 through read to understand the details (Thursday, Friday, Saturday, Sunday: ~2 hours per day)

## Reinforcement Learning and Differential Geometry (14 hours)

### Read Information Geometry Chapter 12  (7 hours)

- [ ] Chapter 12 Section 12.1 

### Introduction to Optimization on Smooth Manifold (7 hours)

## Coursework (6 hours)

- [ ] List the Assignments ( Monday 0.5 hours)
- [ ] Continue the list later


----------------------------------------------------------------------------------------------------------------------

# Weekly Goal (2025/03/24-03/30)
- DP2 Section 1.3 and make some note for DP2 section 1.2
- Send an email to Bryan Wang about the research project 
- QHD need to catch up and write some update to John.

- Kreyszig Chapter 3 and exercises
- Finish assignment 1 for DG
- Finish Homework 2 for Fractals
- Read Chapter 1 of Deep Reinforcement learning
- Read Chapter 12 of Information Geometry
- Complete lecture recording on fractals wk1
- Complete lecture recording on fractals wk2
- Complete lecture recording on fractals wk3
- Complete lecture recording on fractals wk4
- Complete lecture recording on fractals wk5

Idea that I have in mind
- Adaptive control
- PDE and its relation to normal distribution and adverse pde with fat tail distribution
- Multiagent RL for QHD
- Information gemometry, natural gradient descent and its relation to RL
- Semilinear DP, Read papers from Bertsekas.




# Weekly Goal (2025/03/17 - 03/23)
- QHD need to catch up and write some update to John. 
- Kreyszig Chapter 3 and exercises
- Finish Reading DP2 Chapter 1.2 (think why \sigma-chain complete + order continuous has the same power as chain complete + order preserving, i.e., we get up a little bit of completeness but we require more than order preserving to order continuity. what is that a little bit difference between order preserving and order continuity? And can we have \sigma-chain complete and order preserving work? )
- (Done) ~~Finish Reading DP2 Chapter 3.1.1.2-3.1.1.3~~
- (Done) ~~Read the RL survey paper and get a sense of possible research direction~~ --> adaptive control might be lead to QHD
- (Done) ~~Find a possible research direction between differential geometry and RL and talk to Bryan~~ --> Natural Policy Gradient
- Finish assignment 1 for DG
- ~~Finish weekly assignment for week 5 for econometric~~
- ~~Complete lecture recording on DG wk1~~
- ~~Complete lecture recording on DG wk2~~
- ~~Complete lecture recording on DG wk3~~
- ~~Complete lecture recording on DG wk4~~
- ~~Complete lecture recording on DG wk5~~
The lecture for DG is very useless. Refer to the book to get a deeper understanding. Use the lecture only for direction. 

- Complete lecture recording on fractals wk1
- Complete lecture recording on fractals wk2
- Complete lecture recording on fractals wk3
- Complete lecture recording on fractals wk4
- Complete lecture recording on fractals wk5

- List the calender for upcoming assignment (Fractals assignment 2, network video, ECMT week 6 assignment, )

- Read about the information geomtry and its relation to RL, write an email to Bryan Wang to discuss potential research direction. 

Book that need to be read

- neuro-dynamic programming by Bertsekas and Tsitsiklis

- Reinforcement Learning an Introduction by Sutton and Barto
- 
