{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd79475-3a29-4d21-b93c-a58f2e2c0204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "103bb655-c110-4cb0-bcd9-83b60eeb7589",
   "metadata": {},
   "source": [
    "Config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b05d43d-7131-4215-9cdb-f44dec15f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RbcParams:\n",
    "    \"\"\"RBC model parameters\"\"\"\n",
    "    \n",
    "    α:     float = 0.36     # Capital share\n",
    "    η:     float = 0.34     # Labor weight\n",
    "    ρ:     float = 0.918    # TFP shock persistence\n",
    "    β:     float = 0.96     # Discount factor\n",
    "    δ:     float = 0.1      # Depreciation rate\n",
    "    μ_ϵ:   float = 0.0      # Mean of TFP\n",
    "    σ_ϵ:   float = 0.014    # Std of TFP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1fcb4d-3245-4c5b-9334-006df58578a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataclass import dataclass, field\n",
    "from typing import List, Union, Optional\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NetworkParams:\n",
    "    \"\"\" Neural net parameters\"\"\"\n",
    "\n",
    "    in_dim:  int = 2        # input dimension (k_t, a_t)\n",
    "    hid_dim: List[int] = field(default_factory=lambda: [16]) # Hidden layer\n",
    "    out_dim: int = 1  # output dimension (consumption share)\n",
    "    act_fn: Union[str, List[str]] = \"relu\"  # Activation function(s)\n",
    "    dropout_rate: float = 0.0 # Dropout rate\n",
    "    num_batch: int = 100   # Batch size\n",
    "    num_epoch: int = 5000   # Epoch size\n",
    "    optimizer: str = \"adam\"\n",
    "    out_bound: float = 1e-6  # output bound\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Validate activation functions and optimizers\"\"\"\n",
    "\n",
    "        # Valid activtion functions\n",
    "        valid_activations = [\"relu\", \"tanh\", \"sigmoid\"]\n",
    "\n",
    "        if isinstance(self.act_fn, str):\n",
    "            if self.act_fn.lower() not in valid_activations:\n",
    "                raise ValueError(f\"Activation function must be one of: {valid_activations}\")\n",
    "        else:\n",
    "            for act in self.act_fn:\n",
    "                if act.lower() not in valid_activations:\n",
    "                    raise ValueError(f\"Activation function must be one of: {valid_activations}\")\n",
    "\n",
    "        # Valid optimizers\n",
    "        valid_optimzers = [\"adam\", \"sgd\", \"swa\"]\n",
    "        if self.optimizer.lower() not in valid_optimizers:\n",
    "            raise ValueError(f\"Optimizer must be one of: {valid_optimizers}\")\n",
    "\n",
    "        \n",
    "    def get_act_fn(self, idx=0) -> nn.Module:\n",
    "        \"\"\"Convert activation string to PyTorch activation fucntion\"\"\"\n",
    "        if isinstance(self.act_fn, list):\n",
    "            if idx >= len(self.act_fn):\n",
    "                act_name = self.act_fn[-1]\n",
    "            else:\n",
    "                act_name = self.act_fn[idx]\n",
    "        else:\n",
    "            act_name = self.act_fn\n",
    "\n",
    "        act_name = act_name.lower()\n",
    "        if act_name == \"relu\":\n",
    "            return nn.ReLU()\n",
    "        elif act_name == \"tanh\":\n",
    "            return nn.Tanh()\n",
    "        elif act_name == \"sigmoid\":\n",
    "            return nn.Sigmoid()\n",
    "        else: \n",
    "            raise ValueError(f\"Unsupported activation: {act_name}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235ac1c-9738-47b9-b0bd-17dc9ab2c89f",
   "metadata": {},
   "source": [
    "Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06083bff-ef49-44d8-b0a1-2cd5d806bfaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNeuralNetwork\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Neural Network model with configurable architecture\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, params: NetworkParams):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"Neural Network model with configurable architecture\"\"\"\n",
    "    def __init__(self, params: NetworkParams):\n",
    "        \"\"\"Initialize neural network based on provided parameters\"\"\"\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "\n",
    "        # Initialize layers\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(nn.Linear(params.in_dim, params.hid_dim[0]))\n",
    "        if params.dropout_rate > 0:\n",
    "            layers.append(nn.Dropout(p=params.dropout_rate))\n",
    "        layers.append(params.get_act_fn(0))\n",
    "\n",
    "        # Hidden Layers\n",
    "        if i in range(1, len(params.hid_dim)):\n",
    "            layers.append(nn.Linear(params.hid_dim[i-1], params.hid_dim[i]))\n",
    "            if params.dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(p=params.dropout_rate))\n",
    "            layers.append(params.get_act_fn(i))\n",
    "\n",
    "        # Output Layers\n",
    "        layers.append(nn.Linear(params.hid_dim[-1], params.out_dim))\n",
    "\n",
    "        # put the layers together\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network\"\"\"\n",
    "        out = self.layers(x)\n",
    "\n",
    "        # Apply sigmoid to output\n",
    "        ζ_0 = torch.sigmoid(out)\n",
    "\n",
    "        # bound the output\n",
    "        ζ_1 = torch.minimum(\n",
    "            torch.maximum(ζ_0, torch.tensor([params.out_bound])),\n",
    "            torch.tensor([1.0 - params.out_bound])\n",
    "        )\n",
    "\n",
    "        return ζ_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
